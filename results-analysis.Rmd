---
title: "Results Simulation Study"
author: "Florian Stijven"
date: "`r Sys.Date()`"
output: 
  bookdown::html_document2:
    toc: true
bibliography: references.bib
---

```{r setup, include=FALSE}
# Set global markdown options
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
# Load libraries that will be used further on.
library(ggplot2)
library(dplyr)
library(TCT)
```

# Introduction

In this Rmarkdown document, we analyze the results of the simulation study for
assessing the finite sample properties of the meta TCT methods. The primary goal
of this simulation study is to asses to what degree the theoretical asymptotic
results translate to finite samples. The secondary goal is to identify finite
sample settings where the meta TCT methods are not trustworthy. The tertiary
goal is to assess the correctness of the implementation in the `TCT` R-package.

All simulated data sets were generated from multivariate normal distributions 
matching the data generating model (DGM) used by @raket_progression_2022 [Section 5.1].
This DGM represents a realistic 36-months clinical trial in
prodromal Alzheimer's disease. The control group is based on the analysis of a 
selection[^1] of 556 patients from the Alzheimer's disease neuroimaging initiative 
[@veitch2019understanding].

[^1]: The following inclusing criteria were used by @raket_progression_2022: "at
the baseline visit, patients must be diagnosed as having mild cognitive
impairment, score less than or equal to 28 on the mini mental state examination
(MMSE, range 30-0, higher scores indicate less impairment) and be amyloid
positive according to a brain positron emission tomography scan or analysis of
cerebrospinal fluid."

We first present the DGM in more details together with a visualization of the
relevant mean trajectories. Second, the analysis methods we consider in this
simulation study are summarized. Finally, the simulation results are presented.

# Data Generating Model

For the 556 patients selected from the Alzheimer's disease neuroimaging initiative,
the ADAS-cog scores were[^2] available at baseline visits and 6, 12, 18, 24, and 36
months after baseline. The estimated means at the corresponding time points are
$$(19.6, 20.5, 20.9, 22.7, 23.8, 27.4)'$$
and the corresponding estimated covariance matrix is 
$$\begin{pmatrix}
45.1 & 40.0 & 45.1 & 54.9 & 53.6 & 60.8 \\
40.0 & 57.8 & 54.4 & 66.3 & 64.1 & 74.7 \\
45.1 & 54.4 & 72.0 & 80.0 & 77.6 & 93.1 \\
54.9 & 66.3 & 80.0 & 109.8 & 99.3 & 121.7 \\
53.6 & 64.1 & 77.6 & 99.3 & 111.4 & 127.8 \\
60.8 & 74.7 & 93.1 & 121.7 & 127.8 & 191.4
\end{pmatrix}.$$
Patient-level data in the control group are generated from a multivariate normal
distribution with the above mean vector and covariance matrix, as in 
@raket_progression_2022 [Section 5.1]. Whereas @raket_progression_2022 considered
multiple types of treatment effects, we only consider treatment effects that 
correspond to proportional slowing. 

To simulate proportional slowing, we first consider the reference trajectory,
that is, the mean ADAS-cog score in the control group ($Z = 0$) as a function of
time since baseline ($t$), $$f_{0}(t; \boldsymbol{\alpha}) = E(Y_{t} | Z = 0)$$
where $Y_t$ is the ADAScog score $t$ months after baseline. This trajectory
should be a continuous function defined for every time point in the relevant
range, $[0, 36]$. Because we only have 6 mean estimates, at 6 distinct time
points, we interpolate between these 6 points with natural cubic spline
interpolation. This *interpolated* reference trajectory is given in Figure
\@ref(fig:data-generating-model-visualization).

[^2]: 13-item cognitive subscale of the Alzheimerâ€™s disease assessment scale, 
lower scores indicate less impairment [@rosen1984new]

For simulating data from the treated group ($Z = 1$), we consider trajectories of the
following form, $$E(Y_t | Z = 1) = f_0(\gamma \cdot t; \boldsymbol{\alpha}) $$
where $\gamma$ is the proportional slowing factor. These data are simulated from
a multivariate normal distribution with the means determined by the above
trajectory function and with the same covariance matrix as in the control group.

We consider a set of DGMs where the following elements are varied to represent
a range of realistic scenarios:

* **Progression Rate**. We consider a *normal* and *fast* progression rate. The 
normal progression rate corresponds to the mean vector presented above. For the 
fast progression rate, we change the mean vector in the control group to 
$$(18.0, 19.7, 20.9, 22.7, 24.7, 29.2)'.$$ Alternatively, the fast progression 
scenario could also be interpreted as corresponding to trials where patients have
been followed up longer.
* **Treatment Effect**. We consider 3 different (proportional slowing) treatment 
effects, that is, $\gamma \in \{1, 0.75, 0.50 \}$.
* **Sample Size**. We consider 4 different total sample sizes, $n \in \{50, 200, 500, 1000\}$.
Note that $n$ is the total sample size, and we assume $1:1$ randomization in all settings.
* **Duration of follow up**. We consider settings with 24 and 36 months of follow up, 
corresponding to 5 and 6 measurements of the ADAScog score, respectively.

```{r data-generating-model-visualization, fig.cap = "Plot of the trajectories used in the DGMs. A slowing factor equal to 1 corresponds to no treatment effect. The dots represent correspond to measurement occasions while the lines between dots are based on interpolation."}
ref_means_list = list(
  "Normal Progression" = c(19.6, 20.5, 20.9, 22.7, 23.8, 27.4),
  "Fast Progression" = c(18, 19.7, 20.9, 22.7, 24.7, 29.2)
)
time_points = c(0, 6, 12, 18, 24, 36)
time_grid = seq(from = 0,
                to = 36,
                length.out = 3000)
dgm_settings = tidyr::expand_grid(
  progression = c("Normal Progression", "Fast Progression"),
  gamma_slowing = c(1, 0.75, 0.5),
  time_points = list(time_points)
)
trajectory_observed_tbl = dgm_settings %>%
  rowwise(everything()) %>%
  summarise(ref_means = ref_means_list[progression],
            trajectory_points = list(
              spline(
                x = time_points,
                y = ref_means,
                xout = gamma_slowing * unlist(time_points)
              )$y
            )) %>%
  ungroup() %>%
  mutate(treatment = ifelse(gamma_slowing == 1, "Control Treatment", "Active Treatment"))
trajectory_observed_tbl = trajectory_observed_tbl %>%
  rowwise(everything()) %>%
  reframe(tibble(
    trajectory_points = unlist(trajectory_points),
    time_points = unlist(time_points)
  )) %>%
  ungroup() %>%
  mutate(gamma_slowing = as.factor(gamma_slowing))

trajectory_interpolated_tbl = dgm_settings %>%
  rowwise(everything()) %>%
  summarise(
    ref_means = ref_means_list[progression],
    trajectory_interpolated = list(
      spline(
        x = time_points,
        y = ref_means,
        xout = gamma_slowing * time_grid
      )$y
    ),
    time_grid = list(time_grid)
  ) %>%
  ungroup() %>%
  mutate(treatment = ifelse(gamma_slowing == 1, "Control Treatment", "Active Treatment"))
trajectory_interpolated_tbl = trajectory_interpolated_tbl %>%
  rowwise(everything()) %>%
  reframe(tibble(
    trajectory_interpolated = unlist(trajectory_interpolated),
    time_grid = unlist(time_grid)
  )) %>%
  ungroup() %>%
  mutate(gamma_slowing = as.factor(gamma_slowing))

trajectory_observed_tbl %>%
  ggplot(aes(x = time_points, y = trajectory_points)) +
  geom_point(alpha = 0.25) +
  geom_line(
    data = trajectory_interpolated_tbl,
    mapping = aes(
      x = time_grid,
      y = trajectory_interpolated,
      group = interaction(gamma_slowing, treatment, progression),
      color = gamma_slowing
    )
  ) +
  scale_x_continuous(breaks = time_points) +
  scale_color_discrete(type = "seq", name = latex2exp::TeX("Slowing Factor, \\gamma")) +
  xlab("Months After Randomization") +
  ylab("Mean Trajectory") +
  facet_grid( ~ progression)
```

# Analysis Methods

In this section, two analysis methods are briefly outlined. We first present the 
mixed model for repeated measures (MMRM) that is fitted to the simulated data sets.
Next, we discuss the meta TCT methods which use the fitted MMRM. 

## Mixed Model for Repeated Measures

For each simulated data set, a MMRM is fitted. This is a linear mixed model
where time is treated as a categorical covariate. The **systematic part** consists
of the interaction between treatment and time, except for $t = 0$ where we
assume that the mean outcome is equal in both treatment groups. Let $j = 0, 1, ..., K$
denote the measurement occasions, and $t_j$ the corresponding months after baseline.
The mean outcome is then modeled as
$$E(Y_{t_j} | Z = z) = \beta_{z, j} \; \forall \; j \in \{ 1, ..., K \} \text{ and } z \in \{0, 1\}$$
and $E(Y_{0} | Z = 0) = E(Y_{0} | Z = 1) = \beta_0$.
This essentially
means that we have a parameter for each measurement occasion-treatment
combination, except for baseline. The **covariance matrix** is assumed to be
unstructured, but common for both treatment groups.
For all simulation scenarios, this is a correctly specified model. 

These models are fitted using restricted maximum likelihood (REML) using the
`mmrm()` function from the `mmrm` R-package [@mmrmpackage]. The parameter
estimates and corresponding variance-covariance matrix are obtained by the
`coef()` and `vcov()` methods. The hypothesis test for 
$$H_0: \beta_{0, j} = \beta_{1, j} \; \forall \; j \in \{ 1, ..., K \} $$
is based on the F-test with the Kenward-Roger approximate degrees of freedom.

## Meta TCT

TO DO

# Results

In this section, the results of the simulation study are presented and analyzed.
For each setting, we consider $5000$ replications. For estimating coverage of
95\% CIs and empirical type 1 errors, this leads to a standard error of
$\frac{\sqrt{0.05 \cdot 0.95}}{\sqrt{5000}} = 0.003$ assuming nominal coverage and a nominal
type 1 error.

In this section, we focus on the generalized least squares version of meta TCT
where the fitted MMRM is re-estimated to satisfy monotonicity and range
constraints as explained in the documentation of
`TCT::constrained_vertical_estimator()`.

The analyses and presentation of the simulation results are, somewhat
artificially, divided into two parts. First, we present the results regarding
estimation of the acceleration factor. This is the primary goal of the meta TCT
methods: Transforming the treatment effect to an easy to interpret quantity.
Second, we present the results regarding inference. The operations
characteristics of the meta TCT inference procedures are also compared with
these of MMRM.

```{r}
# Read data set with results of the simulation study.
results_tbl = readRDS(file = "results_simulation_lean.rds") %>%
  # We also extract the estimated acceleration factor into a seperate column.
  mutate(estimate = purrr::map_dbl(
    .x = TCT_meta_common_fit,
    .f = coef
  ))
```


## Estimation

To evaluate estimation, we look at 3 key performance measures,

1. **Bias of the estimator.** This is achieve by estimating $E(\hat{\gamma})$ 
across different settings, and comparing the estimated expectation with the 
*true value*, $\gamma_0$.
2. **Mean squared error.** The mean squared error of the estimator is defined as
$E\{(\hat{\gamma} - \gamma_0)^2 \}$. This quantity is estimated as the mean of the 
squared differences between $\hat{\gamma}$ and $\gamma_0$. This quantity quantifies the average
distance between the estimator and the estimand, which depends on the variance and
bias.
3. **Empirical standard deviation.** The empirical standard deviation of the estimator simply
is the standard deviation of the estimator. This measure is estimated as the sample
standard deviation of the estimates in each setting. This value is compared with the
median *estimated standard error*.  

```{r}
# Compute all summary measures regarding the performance of the estimators.
results_tbl_estimation = results_tbl %>%
  # Group by all simulation scenarios.
  group_by(progression, gamma_slowing, n, K, drop_first_occasions, constraints, inference) %>%
  summarise(mean_estimate = mean(estimate),
            empirical_sd = sd(estimate),
            mean_se = mean(se_TCT_common),
            median_se = median(se_TCT_common),
            mse = mean((estimate - gamma_slowing)**2)) %>%
  mutate("Follow Up" = ifelse(K == 6, "36 Months", "24 Months"))
```

In Figure \@ref(fig:expected-value-estimator), the mean estimated acceleration factor
is presented across a set of scenarios. GENERAL BIAS? BIAS in SMALL SAMPLES?

```{r expected-value-estimator, fig.cap = "Graph of mean estimated acceleration factor across a set of simulation settings. The presented results are based on the re-estimated MMRM parameters and least-squares meta TCT. The rows correspond to different true acceleration factors while the columns correspond to the number of post-randomization measures that have been ignored in meta TCT."}
results_tbl_estimation %>%
  filter(constraints == TRUE, inference == "least-squares") %>%
  ggplot(aes(x = n, y = mean_estimate, color = `Follow Up`, linetype = progression)) +
  geom_point() + 
  geom_line() + 
  geom_hline(
    # Add horizontal lines to indicate the true values.
    data = tidyr::expand_grid(gamma_slowing = c(0.5, 0.75, 1), 
                              drop_first_occasions = 0:2),
    mapping = aes(
      yintercept = gamma_slowing
    ),
    alpha = 0.5) +
  xlab("Sample size, n") +
  ylab(latex2exp::TeX("E(\\hat{\\gamma})")) +
  scale_linetype(name = "Progression Rate") +
  facet_grid(gamma_slowing~drop_first_occasions, scales = "free")
```

In Figure \@ref(fig:mse-estimator), the mean squared error of the estimator for the
common acceleration factor is presented across a set of scenarios. As expected,
the MSE decreases as a function of the sample size. Moreover, a longer follow up
and faster progression lead to a smaller MSE.

```{r mse-estimator, fig.cap = "Graph of the mean squared errors of the estimator for the common accleration factor across all simulation settings. The presented results are based on the re-estimated MMRM parameters and least-squares meta TCT. The rows correspond to different true acceleration factors while the columns correspond to the number of post-randomization measures that have been ignored in meta TCT. Note that both axes are log10-transformed."}
results_tbl_estimation %>%
  filter(constraints == TRUE, inference == "least-squares") %>%
  ggplot(aes(x = n, y = mse, color = `Follow Up`, linetype = progression)) +
  geom_point() + 
  geom_line() +
  scale_y_continuous(trans = "log10", name = "MSE") +
  scale_x_continuous(trans = "log10", name = "Sample Size, n") +
    scale_linetype(name = "Progression Rate") +
  facet_grid(gamma_slowing~drop_first_occasions, scales = "free")
```

In Figure \@ref(fig:se-estimator), the empirical standard deviations are plotted 
together with the median estimated standard errors. For small sample size, the
standard error estimator underestimates the empirical standard error. However, 
this underestimation error largely disappears for larger the larger sample sizes.

Although inference is not based directly on the estimated standard error, this 
leads to issues if the estimated acceleration factor would be used in meta-analyses.
We therefore apply the delta method, and parametric bootstrap? (if delta-method work 
fine, not really necessary to go to bootstrap).


```{r se-estimator, fig.cap = "Graph of the empirical standard deviations and the median estimated standard errors of the estimator for the common accleration factor across a set of simulation settings. The dots, and connecting lines, represent the empirical standard deviations. The presented results are based on the re-estimated MMRM parameters and least-squares meta TCT. The rows correspond to different true acceleration factors while the columns correspond to the number of post-randomization measures that have been ignored in meta TCT. The triangles represent the median estimated standard errors."}
results_tbl_estimation %>%
  filter(constraints == TRUE, inference == "least-squares") %>%
  ggplot(aes(
    x = n,
    y = empirical_sd,
    color = `Follow Up`,
    linetype = progression
  )) +
  geom_point() +
  geom_line() +
  geom_point(
    data = results_tbl_estimation %>%
      filter(constraints == TRUE, inference == "least-squares"),
    mapping = aes(x = n, y = median_se),
    shape = 2
  ) +
  scale_y_continuous(trans = "log10", name = "Empirical SD and median estimated SE") +
  scale_x_continuous(trans = "log10", name = "Sample Size, n") +
  scale_linetype(name = "Progression Rate") +
  facet_grid(gamma_slowing ~ drop_first_occasions, scales = "free")
```


## Inference

To evaluate inference, we look at 2 key performance measures,

1. **Type 1 error and power.** We compare the empirical type 1 error with the
nominal rate, $\alpha = 0.05$. We do this for both the meta TCT methods, as for
the MMRM. The former is based on the latter, so we also expect discrepancies
between empirical and nominal type 1 error rates for the MMRM to be reflected in
the meta TCT methods.
2. **Coverage.** We asses the empirical coverage rate of the estimated $95\%$ 
CIs. 



```{r}
# Compute all summary measures regarding the performance of the estimators.
results_tbl_inference = results_tbl %>%
  # Group by all simulation scenarios.
  group_by(progression, gamma_slowing, n, K, drop_first_occasions, constraints, inference) %>%
  summarise(mean_estimate = mean(estimate),
            empirical_sd = sd(estimate),
            mean_se = mean(se_TCT_common),
            mse = mean((estimate - gamma_slowing)**2)) %>%
  mutate("Follow Up" = ifelse(K == 6, "36 Months", "24 Months"))
```

```{r}
results_tbl_inference = results_tbl %>%
  # Extract lower and upper 95% confidence limits into two new columns.
  mutate(lower_conf_int = purrr::map_dbl(.x = conf_int_TCT_common, .f = 1),
         upper_conf_int = purrr::map_dbl(.x = conf_int_TCT_common, .f = 2)) %>%
  mutate(
    # Determine whether the CI contain the true value.
    covered = (gamma_slowing <= upper_conf_int) & (gamma_slowing >= lower_conf_int),
    # Determine whether the null has been rejected
    rejection = p_value_TCT_common <= 0.05,
    rejection_mmrm = p_value_mmrm <= 0.05
    ) %>%
  group_by(progression, gamma_slowing, n, K, drop_first_occasions, constraints, inference) %>%
  summarise(
    coverage = mean(covered),
    rejection_rate = mean(rejection),
    rejection_rate_mmrm = mean(rejection_mmrm)) %>%
  mutate("Follow Up" = ifelse(K == 6, "36 Months", "24 Months"))
```

In Figure \@ref(fig:error-rates-meta-tct), we graph the empirical type 1 error rate and
power. The corresponding operating characteristics for the F-test are superimposed 
in gray. 
This reveals that the type 1 error rate is inflated for ... Consequently, the power 
for the corresponding settings is misleading. 
For ... settings, the type 1 error is close to nominal, hence, the corresponding
empirical powers can be interpreted as such. Comparing these with the power of the
F-test reveals that the meta TCT test yields a higher power in ... 

```{r error-rates-meta-tct, fig.cap = "Graph of empirical type 1 error rates and power across a set of simulation settings. The presented results are based on the re-estimated MMRM parameters and least-squares meta TCT. The rows correspond to different true acceleration factors while the columns correspond to the number of post-randomization measures that have been ignored in meta TCT."}
results_tbl_inference %>%
  filter(constraints == TRUE, inference == "least-squares") %>%
  ggplot(aes(
    x = n,
    y = rejection_rate,
    color = `Follow Up`,
    shape = `Follow Up`,
    linetype = progression
  )) +
  geom_point() +
  geom_line() +
  geom_point(
    data = results_tbl_inference %>%
      filter(constraints == TRUE, inference == "least-squares"),
    mapping = aes(
      x = n,
      y = rejection_rate_mmrm,
      shape = `Follow Up`
    ),
    alpha = 0.5, 
    color = "gray"
  ) +
  geom_line(
    data = results_tbl_inference %>%
      filter(constraints == TRUE, inference == "least-squares"),
    mapping = aes(
      x = n,
      y = rejection_rate_mmrm,
      linetype = progression
    ),
    alpha = 0.75,
    color = "gray"
  ) +
  geom_hline(
    # Add horizontal lines to indicate the 0.05 nominal error rate in the null
    # settings.
    data = tidyr::expand_grid(
      rejection_rate = 0.05,
      drop_first_occasions = 0:2,
      gamma_slowing = 1
    ),
    mapping = aes(yintercept = rejection_rate),
    alpha = 0.5
  ) +
  xlab("Sample size, n") +
  ylab(latex2exp::TeX("Empirical Power or Type 1 Error Rate")) +
  scale_linetype(name = "Progression Rate") +
  facet_grid(gamma_slowing ~ drop_first_occasions, scales = "free")
```

In Figure \@ref(fig:coverage-meta-tct), the empirical coverage rates are presented for 
the same settings as before. 
This reveals that there is undercoverage for ...
For ... settings, coverage is close to nominal. 

```{r coverage-meta-tct, fig.cap = "Graph of empirical coverage across a set of simulation settings. The presented results are based on the re-estimated MMRM parameters and least-squares meta TCT. The rows correspond to different true acceleration factors while the columns correspond to the number of post-randomization measures that have been ignored in meta TCT."}
results_tbl_inference %>%
  filter(constraints == TRUE, inference == "least-squares") %>%
  ggplot(aes(
    x = n,
    y = coverage,
    color = `Follow Up`,
    linetype = progression
  )) +
  geom_point() +
  geom_line() +
    geom_hline(
    # Add horizontal lines to indicate the 0.95 nominal coverage.
    data = tidyr::expand_grid(
      coverage = 0.95,
      drop_first_occasions = 0:2,
      gamma_slowing = c(0.5, 0.75, 1)
    ),
    mapping = aes(yintercept = coverage),
    alpha = 0.5
  ) +
  facet_grid(gamma_slowing ~ drop_first_occasions, scales = "free")
```

# Parametric Bootstrap

In small samples, the operating characteristics of the asymptotic inferential
procedures deviate considerably from nominal. We therefore examine the performance
of a parametric bootstrap in a selected set of settings. 

IDEA OF BS

PERCENTILE CI

RESULTS

# Summary

The results are summarized according to the goals of the simulation study.

Primary goal: Evaluate finite sample properties of the method, also in relation
to asymptotic inference procedures.

* Bias
* MSE, SD, SE,
* CIs and error rates

Secondary goal: Identify settings where the meta TCT methods may yield
untrustworthy results.

* Sample size
* Duration of follow up
* Discarding time points

# Appendix

## All Simulation Settings

In the following table, we summarize the results for all simulation settings.

```{r}
results_tbl_combined = full_join(
  x = results_tbl_estimation,
  y = results_tbl_inference
)
```

```{r}
DT::datatable(results_tbl_combined %>%
                rename("gamma_0" = "gamma_slowing") %>%
                ungroup() %>%
                mutate(across(.cols = where(is.numeric), 
                       .fns = ~ round(.x, digits = 3))), 
              caption = "Summary of all simulation scenarios.", 
              filter = "top")
```

# References




